# 第五章 大数定律及中心极限定理

极限定理是概率论的基本理论，在理论研究和应用中起着重要的作用，其中最重要的是称为“大数定律”与“中心极限定理”的一些定理.大数定律是叙述随机变量序列的前一些项的算术平均值在某种条件下收敛到这些项的均值的算术平均值；中心极限定理则是确定在什么条件下，大量随机变量之和的分布逼近于正态分布.本章介绍几个大数定律和中心极限定理.

# 1 大数定律

第一章曾讲过，大量试验证实，随机事件 A 的频率 $f_n(A)$当重复试验的次数$n$增大时总呈现出稳定性，稳定在某一个常数的附近.频率的稳定性是概率定义的客观基础.本节我们将对频率的稳定性作出理论的说明.
弱大数定律(辛钦大数定律)设$X_1,X_2,\cdotp\cdotp\cdotp$是相互独立$^{\textcircled{1}}$,服从同一分布的随机变量序列，且具有数学期望$E(X_k)=\mu(k=1,2,\cdots).$作前$n$个变量的算术平均$\frac1n\sum_{k=1}^nX_k$,则对于任意 $\varepsilon>0$,有

$$\lim_{n\to\infty}P\bigg\lbrace \:\bigg|\frac{1}{n}\sum_{k=1}^{n}X_{k}-\mu\bigg|<\varepsilon\bigg\rbrace=1.$$

(1.1)

证 我们只在随机变量的方差 $D(X_k)=\sigma^2(k=1,2,\cdots)$存在这一条件下证
明上述结果.因为
$$E\Big(\frac{1}{n}\sum_{k=1}^{n}X_{k}\Big)=\frac{1}{n}\sum_{k=1}^{n}E(X_{k})=\frac{1}{n}n\mu=\mu,$$



又由独立性得

$$D\Big(\frac{1}{n}\sum_{k=1}^{n}X_{k}\Big)=\frac{1}{n^{2}}\sum_{k=1}^{n}D(X_{k})\:=\frac{1}{n^{2}}n\:\sigma^{2}\:=\frac{\sigma^{2}}{n}\:,$$

由切比雪夫不等式(见第四章(2.9)式)得

$1\geqslant P\bigg\lbrace \left|\frac{1}{n}\sum_{k=1}^{n}X_{k}-\mu\right|<\varepsilon\bigg\rbrace\geqslant1-\frac{\sigma^{2}/n}{\varepsilon^{2}}.$

$\textcircled {1}$ 这里指对于任意 $n\geq1,X_1,X_2,...,X_n$ 是相互独立的

在上式中令 $n\to\infty$,即得
$$\begin{aligned}&\text{上式 I J}\\&\operatorname*{lim}_{n\to\infty}P\left\lbrace \:\left|\:\frac{1}{n}\sum_{k=1}^{n}X_{k}-\mu\:\right|<\varepsilon\right\rbrace=1.\\&\left\lbrace \left|\frac{1}{n}\sum_{k=1}^{n}X_{k}-\mu\right|<\varepsilon\right\rbrace\text{是一个随机事件}.\text{等式}(1.1)\text{表明},\text{当 }n\to\infty\text{时这个事}\\\end{aligned}$$



牛的概率趋于1.即对于任意正数ε,当$n$充分大时，不等式$\left|\frac1n\sum_{k=1}^nX_k-\mu\right|<\varepsilon$ 成立的概率很大.通俗地说，辛钦大数定律是说，对于独立同分布且具有均值$\mu$的随机变量 $X_1,X_2,\cdotp\cdotp\cdotp,X_n$,当 $n$ 很 大 时 它 们 的 算 术 平 均 $\frac 1n\sum _{i= 1}^nX_k$ 很 可 能 接 近 于 $\mu .$
设$Y_1,Y_2,\cdots,Y_n,\cdots$是一个随机变量序列，$a$ 是一个常数.若对于任意正数 ε,有
$$\lim_{n\to\infty}P\lbrace \mid Y_{n}-a\mid<\varepsilon\rbrace=1\:,$$

则称序列$Y_1,Y_2,\cdots,Y_n,\cdots$依概率收敛于$a$,记为
$Y_n\xrightarrow{P}a.$

依概率收敛的序列有以下的性质.

设 $X_{n}\xrightarrow{P}a,Y_{n}\xrightarrow{P}b$,又设函数 $g(x,y)$在点$(a,b)$连续，则

$g($ $X_n$ $, Y_n$ $) \xrightarrow{P}g($ $a$ $, b) .$ (证略.)

这样，辛钦大数定律又可叙述为：
弱大数定律(辛钦大数定律) 设随机变量 $X_1,X_2,\cdotp\cdotp\cdotp,X_n,\cdotp\cdotp\cdotp$相互独立，服从同一分布且具有数学期望$E(X_k)=\mu(k=1,2,\cdots)$,则序列$\overline{X}=\frac1n\sum_{k=1}^nX_k$ 依概率收敛于 $\mu$,即 $\overline{X}\xrightarrow P\mu.$
下面介绍辛钦大数定律的一个重要推论.
伯努利大数定律 设$f_\mathrm{A}$是$n$次独立重复试验中事件 A 发生的次数，$p$是
事件 A 在每次试验中发生的概率，则对于任意 $\epsilon>0$,有

(1.2)

$$\lim_{n\to\infty}P\bigg\lbrace \:\bigg|\frac{f_A}{n}-p\bigg|<\varepsilon\bigg\rbrace=1$$
$$\lim_{n\to\infty}P\bigg\lbrace \:\bigg|\frac{f_A}{n}-p\bigg|\geqslant\varepsilon\bigg\rbrace=0.$$

或

$(1.2)^{\prime}$

证 因为 $f_{A}\sim b(n,p)$,由第四章§2例6，有
$$f_A=X_1+X_2+\cdots+X_n\:,$$



其中$,X_1,X_2,\cdots,X_n$ 相互独立，且都服从以 $p$ 为参数的(0-1)分布，因而$E(X_k)=$
$p$ $( k= 1, 2, \cdots , n)$,由(1.1)式即得

$$\operatorname*{lim}_{n\to\infty}P\bigg\lbrace \:\bigg|\:\frac{1}{n}\sum_{k=1}^{n}X_{k}-p\:\bigg|<\varepsilon\bigg\rbrace=\:1\:,\\\operatorname*{lim}_{n\to\infty}P\bigg\lbrace \:\bigg|\:\frac{f_{A}}{n}-p\bigg|\geqslant\varepsilon\bigg\rbrace=0.$$

即

口

伯努利大数定律的结果表明，对于任意 $\varepsilon>0$,只要重复独立试验的次数 $n$ 充分大，事件$\left\lbrace \left|\frac{f_{A}}{n}-p\right|\geqslant\varepsilon\right\rbrace$是一个小概率事件，由实际推断原理知(见第一章$\S$4),这一事件实际上几乎是不发生的，即在 $n$ 充分大时事件$\left|\left|\frac{f_{A}}n-p\right|<\varepsilon\right|$实际上几乎是必定要发生的，亦即对于给定的任意小的正数ε,在$n$充分大时，事件“频率$\frac{f_{\mathrm{A}}}n$与概率 $p$ 的偏差小于 ε”实际上几乎是必定要发生的.这就是我们所说的频率稳定性的真正含义.由实际推断原理，在实际应用中，当试验次数很大时，便可以用事件的频率来代替事件的概率.

## 82中心极限定理

在客观实际中有许多随机变量，它们是由大量的相互独立的随机因素的综合影响所形成的.而其中每一个别因素在总的影响中所起的作用都是微小的.这种随机变量往往近似地服从正态分布.这种现象就是中心极限定理的客观背景. 本节只介绍三个常用的中心极限定理.
定理 1(独立同分布的中心极限定理) 设随机变量 $X_1,X_2,\cdots,X_n,\cdots$相互独立，服从同一分布，且具有数学期望和方差：$E(X_k)=\mu,D(X_k)=\sigma^2>0$($k=1$, $2,\cdots)$,则随机变量之和$\sum_k=1^{n}X_k$ 的标准化变量

$$\begin{aligned}&\sum_{k=1}^{n}X_{k}-E\Big(\sum_{k=1}^{n}X_{k}\Big)\\&Y_{n}=\frac{\sum_{k=1}^{n}X_{k}-E\Big(\sum_{k=1}^{n}X_{k}\Big)}{\sqrt{D\left(\sum_{k=1}^{n}X_{k}\right)}}=\frac{\sum_{k=1}^{n}X_{k}-n\mu}{\sqrt{n}\sigma}\\\end{aligned}$$

的分布函数$F_n(x)$对于任意$x$满足
$$\begin{aligned}\text{对于任意 }x\text{ 满足}\\\operatorname*{lim}_{n\to\infty}F_{n}(x)&=\operatorname*{lim}_{n\to\infty}P\biggl\lbrace \frac{\sum_{k=1}^{n}X_{k}-n\mu}{\sqrt{n}\sigma}\leqslant x\biggr\rbrace\\&=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\:\mathrm{d}t\:=\:\Phi(\:x\:).\end{aligned}$$


(2.1)

证明略.

这就是说，均值为$\mu$,方差为$\sigma^2>0$的独立同分布的随机变量$X_1,X_2,\cdots,X_n$
之和$\sum_k=1^{^{^{\prime}}}X_{k}$ 的标准化变量，当 $n$ 充分大时，有

$$\frac{\sum\limits_{k=1}^nX_k-n\mu}{\sqrt{n}\sigma}\underbrace{\text{近似地}}_{N(0,1).}$$

(2.2)

在一般情况下，很难求出$n$个随机变量之和$\sum_kX_k$的分布函数，(2.2)式表明，当$n$充分大时，可以通过$\Phi(x)$给出其近似的分布.这样，就可以利用正态分布对 $\sum_{k=1}^{\pi}X_k$ 作理论分析或作实际计算，其好处是明显的.

将(2.2)式左端改写成$\frac{\frac1n\sum_{k=1}^nX_k-\mu}{\sigma/\sqrt{n}}=\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}$,这样，上述结果可写成：当 $n$

充分大时，

$$\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\xrightarrow{\text{近似地}}N(0,1)\quad\text{或}\quad\overline{X}\xrightarrow{\text{近似地}}N(\mu,\sigma^2/n)\:.$$

(2.3)


这是独立同分布的中心极限定理结果的另一个形式，这就是说，均值为 $\mu$,方差为$\sigma^2>0$的独立同分布的随机变量$X_1,X_2,\cdotp\cdotp\cdotp,X_n$的算术平均$\overline{X}=\frac1n\sum_{i=1}^nX_k$, 当$n$ 充 分 大 时 近 似 地 服 从 均 值 为 $\mu$,方差为$\sigma^2/n$的正态分布.这一结果是数理统计中大样本统计推断的基础，
定理 2(李雅普诺夫(Lyapunov)定理) 设随机变量 $X_1,X_2,\cdots,X_n,\cdots$相互
独立，它们具有数学期望和方差
$$E(X_k)=\mu_k\:,\quad D(X_k)=\sigma_k^2>0\:,\quad k=1\:,2\:,\cdots,$$

$$B_n^2=\sum_{k=1}^n\sigma_k^2.$$

记


若存在正数 $\delta$,使得当 $n\to\infty$时，

$$\frac{1}{B_{n}^{2+\delta}}\:\sum_{k=1}^{n}E\lbrace \mid X_{k}-\mu_{k}\mid^{2+\delta}\rbrace\to0\:,$$

则随机变量之和$\sum_k=1^nX_k$的标准化变量

$$Z_{n}=\frac{\sum_{k=1}^{n}X_{k}-E\Big(\sum_{k=1}^{n}X_{k}\Big)}{\sqrt{D\Big(\sum_{k=1}^{n}X_{k}\Big)}}=\frac{\sum_{k=1}^{n}X_{k}-\sum_{k=1}^{n}\mu_{k}}{B_{n}}$$

的分布函数 $F_n(x)$对于任意 $x$,满足
$$\begin{aligned}\lim_{n\to\infty}F_{n}(x)&=\lim_{n\to\infty}P\biggl\lbrace \frac{\sum_{k=1}^{n}X_{k}-\sum_{k=1}^{n}\mu_{k}}{B_{n}}\leqslant x\biggr\rbrace\\&=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\:\mathrm{d}t=\Phi(x).\end{aligned}$$


(2.4)

证明略.
定理 2 表明 ,在定理的条件下，随机变量


$$Z_n=\frac{\sum_{k=1}^nX_k-\sum_{k=1}^n\mu_k}{B_n}$$

$当n$很大时，近似地服从正态分布 N(0,1).由此，当$n$很大时，$\sum_k=1^{n}X_{k}=B_{n}Z_{n}+\sum_{b=1}^{n}\mu$ 近似地服从正态分布 N$\left(\sum_{i=1}^n\mu_k,B_n^2\right).$这就是说，无论各个随机变量$X_k\left(k=1,\right)$ $2,\cdots)服从什么分布，只要满足定理的条件，那么它们的和\sum_{k=1}^nX_k$ 当$n$ 很大时，就近似地服从正态分布.这就是正态随机变量在概率论中占有重要地位的一个基本原因，在很多问题中，所考虑的随机变量可以表示成很多个独立的随机变量之和.例如，在任一指定时刻，一个城市的耗电量是大量用户耗电量的总和；一个物理实验的测量误差是由许多观察不到的、可加的微小误差所合成的，它们往往近似地服从正态分布.
下面介绍另一个中心极限定理，它是定理 1 的特殊情况.
定理 3(棣莫弗-拉普拉斯(De Moivre-Laplace)定理)设随机变量
$\eta_n(n=1,2,\cdotp\cdotp\cdotp)$服从参数为 $n,p(0<p<1)$的二项分布，则对于任意 $x$,有
$$\lim_{n\to\infty}P\left\lbrace \frac{\eta_{n}-np}{\sqrt{np\left(1-p\right)}}\leqslant x\right\rbrace=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\:\mathrm{d}t=\Phi(x)\:.$$

(2.5)


证 由第四章§2例6知可以将$\eta_\mathrm{\pi}$分解成为$n$个相互独立、服从同一(0-1)
分布的诸随机变量 $X_1,X_2,\cdotp\cdotp\cdotp,X_n$ 之和，即有

$$\eta_n\:=\:\sum_{k\:=\:1}^nX_k\:,$$

其中$X_{k}(k=1,2,\cdots,n)$的分布律为

$P\left \lbrace  X_k= i\right \rbrace = p^i\left ( 1- p\right ) ^{1- i}$, $. i= 0, 1.$

由于$E(X_{k})=p,D(X_{k})=p(1-p)(k=1,2,\cdots,n)$,由定理1得

$$\begin{aligned}&\lim_{n\to\infty}P\left\lbrace \frac{\eta_{n}-np}{\sqrt{np\left(1-p\right)}}\leqslant x\right\rbrace&&=\lim_{n\to\infty}P\left\lbrace \frac{\sum_{k=1}^{n}X_{k}-np}{\sqrt{np\left(1-p\right)}}\leqslant x\right\rbrace\\&&&=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\:\mathrm{d}t\:=\:\Phi(x)\:.\end{aligned}$$

口

这个定理表明，正态分布是二项分布的极限分布.当$n$充分大时，我们可以利
用(2.5)式来计算二项分布的概率.下面举几个关于中心极限定理应用的例子.
例 1 一加法器同时收到 20 个噪声电压$V_k(k=1,2,\cdots,20)$,设它们是相互独立的随机变量，且都在区间(0,10)上服从均匀分布.记$V=\sum_{k=1}^{20}V_k$,求$P\left\lbrace V{>}105\right\rbrace$的近似值.
解 易知 $E(V_k)=5,D(V_k)=100/12(k=1,2,\cdots,20).$由定理 1,随机变量

$$Z=\frac{\sum\limits_{k=1}^{20}V_k-20\times5}{\sqrt{100/12}\sqrt{20}}=\frac{V-20\times5}{\sqrt{100/12}\sqrt{20}}$$

近似服从正态分布 N(0,1),于是
$$\begin{aligned}P\langle V>105\rangle&=P\biggl\lbrace \frac{V-20\times5}{(10/\sqrt{12})\sqrt{20}}>\frac{105-20\times5}{(10/\sqrt{12})\sqrt{20}}\biggr\rbrace\\&=P\biggl\lbrace \frac{V-100}{(10/\sqrt{12})\sqrt{20}}>0.387\biggr\rbrace\\&=1-P\biggl\lbrace \frac{V-100}{(10/\sqrt{12})\sqrt{20}}\leqslant0.387\biggr\rbrace\\&\approx1-\int_{-\infty}^{0.387}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\mathrm{d}t=1-\Phi(0.387)=0.348.\end{aligned}$$

$P\lbrace V>105\rbrace\approx0.348.$

口

即有

例 2 一船舶在某海区航行，已知每遭受一次波浪的冲击，纵摇角大于 3°的概率为 $p=1/3$,若船舶遭受了90 000 次波浪冲击，问其中有 29 500~30 500 次纵摇角度大于 3°的概率是多少？
解 我们将船舶每遭受一次波浪冲击看作一次试验，并假定各次试验是独

立的.在 90 000 次波浪冲击中纵摇角度大于 3°的次数记为$X$,则$X$是一个随机
变量，且有 $X\sim b(90000,1/3).$其分布律为

$$P\lbrace X=k\rbrace=\binom{90\:000}{k}\left(\frac{1}{3}\right)^k\left(\frac{2}{3}\right)^{90\:000-k},\quad k=0\:,1\:,\cdots,90\:000.$$

所求的概率为
$$P\lbrace 29\:500\leqslant X\leqslant30\:500\rbrace=\sum_{k=29\:500}^{30\:500}\binom{90\:000}{k}\left(\frac{1}{3}\right)^{k}\left(\frac{2}{3}\right)^{90\:000-k}\:,$$



要直接计算是麻烦的，我们利用棣莫弗一拉普拉斯定理来求它的近似值.即有
$P\lbrace 29500\leqslant X\leqslant30500\rbrace$

$$=P\left\lbrace \frac{29\:500-np}{\sqrt{np\:(1-p)}}\leqslant\frac{X-np}{\sqrt{np\:(1-p)}}\leqslant\frac{30\:500-np}{\sqrt{np\:(1-p)}}\right\rbrace$$
$$\approx\int_{\frac{29\:500-qp}{\sqrt{np(1-p)}}}^{\frac{30\:500-qp}{\sqrt{np(1-p)}}}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\:\mathrm{d}t=\Phi\Big(\frac{30\:500-np}{\sqrt{np(1-p)}}\Big)-\Phi\Big(\frac{29\:500-np}{\sqrt{np(1-p)}}\Big)\:,$$

其中$n=90000,p=1/3.$即有

$\square$

$$P\lbrace 29\:500\leqslant X\leqslant30\:500\rbrace\approx\Phi\Big(\frac{5\sqrt{2}}{2}\Big)-\Phi\Big(-\frac{5\sqrt{2}}{2}\Big)=0.999\:5.$$

例 3 对于一个学生而言，来参加家长会的家长人数是一个随机变量，设一个学生无家长、有 1 名家长、有 2 名家长来参加会议的概率分别为 0.05、0.8、 0.15.若学校共有 400 名学生，设各学生参加会议的家长人数相互独立，且服从同一分布.
(1)求参加会议的家长人数 X 超过 450 的概率.
(2)求有 1名家长来参加会议的学生人数不多于 340 的概率.
解(1)以$X_k(k=1,2,\cdots,400)$记第$k$个学生来参加会议的家长人数，则
$X_k$的分布律为

$$\begin{array}{c|cccccc}X_k&&0&&1&&2\\\hline p_k&&0.05&&0.8&&0.15\end{array}.$$

易知$E(X_{k})=1.1,D(X_{k})=0.19,k=1,2,\cdots,400.$而$X=\sum_k=1^{400}X_{k}$.由定理 1
随机变量

$$\dfrac{\sum\limits_{k=1}^{400}X_k-400\times1.1}{\sqrt{400}\:\sqrt{0.19}}=\dfrac{X-400\times1.1}{\sqrt{400}\:\sqrt{0.19}}$$

近似服从正态分布 N(0,1),于是$$P\left\lbrace X>450\right\rbrace=P\left\lbrace \frac{X-400\times1.1}{\sqrt{400}\:\sqrt{0.19}}>\frac{450-400\times1.1}{\sqrt{400}\:\sqrt{0.19}}\right\rbrace\\=1-P\left\lbrace \frac{X-400\times1.1}{\sqrt{400}\:\sqrt{0.19}}\leqslant1.\:147\right\rbrace\\\approx1-\Phi(1.147)=0.125\:1.$$


(2)以$Y$记有 1名家长参加会议的学生人数，则$Y\sim b(400,0.8)$,由定理 3,

$$P\left\lbrace Y\leqslant340\right\rbrace=P\left\lbrace \frac{Y-400\times0.8}{\sqrt{400\times0.8\times0.2}}\leqslant\frac{340-400\times0.8}{\sqrt{400\times0.8\times0.2}}\right\rbrace$$
$= P\left \lbrace  \frac {Y- 400\times 0. 8}{\sqrt {400\times 0. 8\times 0. 2}}\leqslant 2. 5\right \rbrace \approx \Phi ( 2. 5) = 0. 993$ 8. $\square$

小结

人们在长期实践中认识到频率具有稳定性，即当试验次数不断增大时，频率稳定在一个数的附近$\cdot$这一事实显示了可以用一个数来表征事件发生的可能性的大小.这使人们认识到概率是客观存在的，进而由频率的性质的启发和抽象给出了概率的定义，因而频率的稳定性是概率定义的客观基础.伯努利大数定律则以严密的数学形式论证了频率的稳定性.
中心极限定理表明，在相当一般的条件下，当独立随机变量的个数不断增加时，其和的分布趋于正态分布.这一事实阐明了正态分布的重要性，也揭示了为什么在实际应用中会经常遇到正态分布，也就是揭示了产生正态分布变量的源泉.另一方面，它提供了独立同分布随机变量之和$\sum_{i=1}^{n}X_k$ (其中$X_k$的方差存在)的近似分布，只要和式中加项的个数充分大，就可以不必考虑和式中的随机变量服从什么分布，都能用正态分布来近似，这在应用上是有效和重要的.
中心极限定理的内容包含极限，因而称它为极限定理是很自然的.又由于它在统计中的
重要性，称它为中心极限定理，这是波利亚(Pólya)在 1920 年取的名字.
◼重要术语及主题


依概率收敛 伯努利大数定律 辛钦大数定律 独立同分布的中心极限定理 李雅普

诺夫中心极限定理 棣莫弗一拉普拉斯中心极限定理


